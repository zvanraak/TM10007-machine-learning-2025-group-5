{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7SXpaKwwGe5x"
   },
   "source": [
    "# TM10007 Assignment template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 69
    },
    "colab_type": "code",
    "id": "CiDn2Sk-VWqE",
    "outputId": "64224cd2-6054-4b04-a3f6-af8290400dfc"
   },
   "outputs": [],
   "source": [
    "# Run this to use from colab environment\n",
    "#!pip install -q --upgrade git+https://github.com/jveenland/tm10007_ml.git"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data loading and cleaning\n",
    "\n",
    "Below are functions to load the dataset of your choice. After that, it is all up to you to create and evaluate a classification method. Beware, there may be missing values in these datasets. Good luck!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-NE_fTbKGe5z"
   },
   "outputs": [],
   "source": [
    "# Data loading functions. Uncomment the one you want to use\n",
    "#from worcgist.load_data import load_data\n",
    "from worclipo.load_data import load_data\n",
    "#from worcliver.load_data import load_data\n",
    "#from ecg.load_data import load_data\n",
    "\n",
    "# Import classifiers\n",
    "from sklearn import model_selection\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "\n",
    "data = load_data()\n",
    "print(f'The number of samples: {len(data.index)}')\n",
    "print(f'The number of columns: {len(data.columns)}')\n",
    "\n",
    "X = data.drop(\"label\",axis=1)\n",
    "y = data[\"label\"]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "for fold, (train_idx, val_idx) in enumerate(skf.split(X_train, y_train), 1):\n",
    "    X_train_fold = X_train.iloc[train_idx]\n",
    "    y_train_fold = y_train.iloc[train_idx]\n",
    "    X_val_fold = X_train.iloc[val_idx]\n",
    "    y_val_fold = y_train.iloc[val_idx]\n",
    "\n",
    "    print(f\"Fold {fold}:\")\n",
    "    print(f\" - Train size: {len(X_train_fold)}\")\n",
    "    print(f\" - Validation size: {len(X_val_fold)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "General functions to be used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some functions we will use\n",
    "def colorplot(clf, ax, x, y, h=100, precomputer=None):\n",
    "    '''\n",
    "    Overlay the decision areas as colors in an axes.\n",
    "\n",
    "    Input:\n",
    "        clf: trained classifier\n",
    "        ax: axis to overlay color mesh on\n",
    "        x: feature on x-axis\n",
    "        y: feature on y-axis\n",
    "        h(optional): steps in the mesh\n",
    "    '''\n",
    "    # Create a meshgrid the size of the axis\n",
    "    xstep = (x.max() - x.min() ) / 20.0\n",
    "    ystep = (y.max() - y.min() ) / 20.0\n",
    "    x_min, x_max = x.min() - xstep, x.max() + xstep\n",
    "    y_min, y_max = y.min() - ystep, y.max() + ystep\n",
    "    h = max((x_max - x_min, y_max - y_min))/h\n",
    "    xx, yy = np.meshgrid(np.arange(x_min, x_max, h),\n",
    "                         np.arange(y_min, y_max, h))\n",
    "\n",
    "    features = np.c_[xx.ravel(), yy.ravel()]\n",
    "    if precomputer is not None:\n",
    "        if type(precomputer) is RBFSampler:\n",
    "            features = precomputer.transform(features)\n",
    "        elif precomputer is rbf_kernel:\n",
    "            features = rbf_kernel(features, X)\n",
    "\n",
    "    # Plot the decision boundary. For that, we will assign a color to each\n",
    "    # point in the mesh [x_min, x_max]x[y_min, y_max].\n",
    "    if hasattr(clf, \"decision_function\"):\n",
    "        Z = clf.decision_function(features)\n",
    "    else:\n",
    "        Z = clf.predict_proba(features)\n",
    "    if len(Z.shape) > 1:\n",
    "        Z = Z[:, 1]\n",
    "\n",
    "    # Put the result into a color plot\n",
    "    cm = plt.cm.RdBu_r\n",
    "    Z = Z.reshape(xx.shape)\n",
    "    ax.contourf(xx, yy, Z, cmap=cm, alpha=.8)\n",
    "    del xx, yy, x_min, x_max, y_min, y_max, Z, cm\n",
    "\n",
    "def plot_learning_curve(estimator, title, X, y, axes, ylim=None, cv=None,\n",
    "                        n_jobs=None, train_sizes=np.linspace(.1, 1.0, 5)):\n",
    "    \"\"\"\n",
    "    Generate 3 plots: the test and training learning curve, the training\n",
    "    samples vs fit times curve, the fit times vs score curve.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    estimator : object type that implements the \"fit\" and \"predict\" methods\n",
    "        An object of that type which is cloned for each validation.\n",
    "\n",
    "    title : string\n",
    "        Title for the chart.\n",
    "\n",
    "    X : array-like, shape (n_samples, n_features)\n",
    "        Training vector, where n_samples is the number of samples and\n",
    "        n_features is the number of features.\n",
    "\n",
    "    y : array-like, shape (n_samples) or (n_samples, n_features), optional\n",
    "        Target relative to X for classification or regression;\n",
    "        None for unsupervised learning.\n",
    "\n",
    "    axes : array of 3 axes, optional (default=None)\n",
    "        Axes to use for plotting the curves.\n",
    "\n",
    "    ylim : tuple, shape (ymin, ymax), optional\n",
    "        Defines minimum and maximum yvalues plotted.\n",
    "\n",
    "    cv : int, cross-validation generator or an iterable, optional\n",
    "        Determines the cross-validation splitting strategy.\n",
    "        Possible inputs for cv are:\n",
    "          - None, to use the default 5-fold cross-validation,\n",
    "          - integer, to specify the number of folds.\n",
    "          - :term:`CV splitter`,\n",
    "          - An iterable yielding (train, test) splits as arrays of indices.\n",
    "\n",
    "        For integer/None inputs, if ``y`` is binary or multiclass,\n",
    "        :class:`StratifiedKFold` used. If the estimator is not a classifier\n",
    "        or if ``y`` is neither binary nor multiclass, :class:`KFold` is used.\n",
    "\n",
    "        Refer :ref:`User Guide <cross_validation>` for the various\n",
    "        cross-validators that can be used here.\n",
    "\n",
    "    n_jobs : int or None, optional (default=None)\n",
    "        Number of jobs to run in parallel.\n",
    "        ``None`` means 1 unless in a :obj:`joblib.parallel_backend` context.\n",
    "        ``-1`` means using all processors. See :term:`Glossary <n_jobs>`\n",
    "        for more details.\n",
    "\n",
    "    train_sizes : array-like, shape (n_ticks,), dtype float or int\n",
    "        Relative or absolute numbers of training examples that will be used to\n",
    "        generate the learning curve. If the dtype is float, it is regarded as a\n",
    "        fraction of the maximum size of the training set (that is determined\n",
    "        by the selected validation method), i.e. it has to be within (0, 1].\n",
    "        Otherwise it is interpreted as absolute sizes of the training sets.\n",
    "        Note that for classification the number of samples usually have to\n",
    "        be big enough to contain at least one sample from each class.\n",
    "        (default: np.linspace(0.1, 1.0, 5))\n",
    "    \"\"\"\n",
    "\n",
    "    axes.set_title(title)\n",
    "    if ylim is not None:\n",
    "        axes.set_ylim(*ylim)\n",
    "    axes.set_xlabel(\"Training examples\")\n",
    "    axes.set_ylabel(\"Score\")\n",
    "\n",
    "    train_sizes, train_scores, test_scores  = \\\n",
    "        learning_curve(estimator, X, y, cv=cv, n_jobs=n_jobs,\n",
    "                       train_sizes=train_sizes)\n",
    "    train_scores_mean = np.mean(train_scores, axis=1)\n",
    "    train_scores_std = np.std(train_scores, axis=1)\n",
    "    test_scores_mean = np.mean(test_scores, axis=1)\n",
    "    test_scores_std = np.std(test_scores, axis=1)\n",
    "\n",
    "    # Plot learning curve\n",
    "    axes.grid()\n",
    "    axes.fill_between(train_sizes, train_scores_mean - train_scores_std,\n",
    "                         train_scores_mean + train_scores_std, alpha=0.1,\n",
    "                         color=\"r\")\n",
    "    axes.fill_between(train_sizes, test_scores_mean - test_scores_std,\n",
    "                         test_scores_mean + test_scores_std, alpha=0.1,\n",
    "                         color=\"g\")\n",
    "    axes.plot(train_sizes, train_scores_mean, 'o-', color=\"r\",\n",
    "                 label=\"Training score\")\n",
    "    axes.plot(train_sizes, test_scores_mean, 'o-', color=\"g\",\n",
    "                 label=\"Cross-validation score\")\n",
    "    axes.legend(loc=\"best\")\n",
    "\n",
    "    return plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Missing data\n",
    "* Part 1: Finding missing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define missing value indicators\n",
    "custom_missing = ['NA', 'N/A', '?', 'None', 'none', '-']\n",
    "\n",
    "# Count NaNs\n",
    "nan_counts = X_train.isna().sum()\n",
    "\n",
    "# Count empty strings\n",
    "empty_string_counts = (X_train == '').sum()\n",
    "\n",
    "# Count custom missing indicators (case-insensitive match)\n",
    "custom_missing_counts = X_train.apply(lambda col: col.astype(str).str.lower().isin([val.lower() for val in custom_missing]).sum())\n",
    "\n",
    "# Compute total missing count per column\n",
    "total_missing = nan_counts + empty_string_counts + custom_missing_counts\n",
    "\n",
    "# Filter out columns where total missing is zero\n",
    "total_missing_selected = total_missing[total_missing != 0]\n",
    "\n",
    "# Print total missing counts\n",
    "print(total_missing_selected)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Part 2: Processing missing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import\n",
    "import numpy as np\n",
    "from sklearn.impute import SimpleImputer\n",
    "from scipy.stats import shapiro\n",
    "\n",
    "# Replacing missing values with NaN\n",
    "custom_missing = ['NA', 'N/A', '?', 'None', 'none', '-', '']\n",
    "X_train.replace(custom_missing, np.nan, inplace=True)\n",
    "X_test.replace(custom_missing, np.nan, inplace=True)\n",
    "\n",
    "# If 50% or more of the data within one feature is missing the feature is deleted\n",
    "limit = len(X_train.index)*50/100\n",
    "valid_columns = [col for col, count in total_missing.items() if count < limit]\n",
    "\n",
    "# Keep only the valid columns in both X_train and X_test\n",
    "X_train = X_train[valid_columns]\n",
    "X_test = X_test[valid_columns]\n",
    "\n",
    "# Imputate \n",
    "\n",
    "# Check if imputation is needed\n",
    "if X_train.isna().sum().sum() == 0:\n",
    "    pass\n",
    "else:\n",
    "    # Dictionary to store mean/median decision per column\n",
    "    imputation_strategies = {}\n",
    "\n",
    "    for col in X_train.select_dtypes(include=['number']).columns:  # Only numeric columns\n",
    "        col_data = X_train[col].dropna()  # Remove NaN values for testing\n",
    "\n",
    "        if len(col_data) > 3:  # Shapiro requires at least 3 non-null values\n",
    "            if col_data.nunique() == 1:  # Check if all values are the same\n",
    "                strategy = 'median'  # Default to median if no variability\n",
    "            else:\n",
    "                _, p = shapiro(col_data)\n",
    "                strategy = 'mean' if p > 0.05 else 'median'\n",
    "        else:\n",
    "            strategy = 'median'  # Default to median if too few values\n",
    "\n",
    "        imputation_strategies[col] = strategy\n",
    "\n",
    "    # Create imputers for mean and median\n",
    "    mean_imputer = SimpleImputer(strategy='mean')\n",
    "    median_imputer = SimpleImputer(strategy='median')\n",
    "\n",
    "    # Apply imputers for each feature\n",
    "    for col, strategy in imputation_strategies.items():\n",
    "        imputer = mean_imputer if strategy == 'mean' else median_imputer\n",
    "        X_train[col] = imputer.fit_transform(X_train[[col]])\n",
    "        X_test[col] = imputer.transform(X_test[[col]])  # Use the same imputer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scaling data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn import preprocessing\n",
    "\n",
    "scaler_robust = preprocessing.RobustScaler()\n",
    "\n",
    "scaled_robust_array_train = scaler_robust.fit_transform(X_train)\n",
    "scaled_robust_array_test = scaler_robust.transform(X_test)\n",
    "\n",
    "X_scaled_robust_train = pd.DataFrame(scaled_robust_array_train, columns=X_train.columns)\n",
    "X_scaled_robust_test = pd.DataFrame(scaled_robust_array_test, columns=X_test.columns)\n",
    "\n",
    "# print(X_scaled_robust_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lloyd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rfecv en svm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recursive Feature Elimination with Cross-Validation (RFECV)\n",
    "\n",
    "# Import libraries\n",
    "from sklearn import feature_selection\n",
    "from sklearn import svm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# calling the classifier (SVM model) for the feature selection\n",
    "svc = svm.SVC(kernel=\"linear\")\n",
    "\n",
    "# RFECV feature selection and fitting\n",
    "rfecv = feature_selection.RFECV(\n",
    "    estimator=svc, step=5,\n",
    "    cv=model_selection.StratifiedKFold(n_splits=2, shuffle=True, random_state=42),\n",
    "    scoring='roc_auc',\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "rfecv.fit(X_train, y_train)\n",
    "\n",
    "# print selected feature names\n",
    "selected_features = X_train.columns[sfs1.get_support()]\n",
    "print(\"Selected features:\", selected_features)\n",
    "\n",
    "# plot the number of features vs. accuracy\n",
    "plt.figure()\n",
    "plt.xlabel(\"Number of features selected\")\n",
    "plt.ylabel(\"Mean test accuracy\")\n",
    "plt.plot(range(1, len(rfecv.cv_results_[\"mean_test_score\"]) + 1), rfecv.cv_results_[\"mean_test_score\"])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Univariate testing (ANOVA) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SelectKBest, f_classif, mutual_info_classif\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Zet de labels om naar numerieke waarden\n",
    "le = LabelEncoder()\n",
    "y_train_numeric = le.fit_transform(y_train)\n",
    "legend_labels = le.classes_  # Toont de mapping van labels naar nummers\n",
    "\n",
    "# ANOVA F-test (lineaire relaties)\n",
    "selector_anova = SelectKBest(f_classif, k=40)\n",
    "X_filtered_anova = selector_anova.fit_transform(X_scaled_robust_train, y_train)\n",
    "anova_features = X_scaled_robust_train.columns[selector_anova.get_support()]\n",
    "# print(anova_features)\n",
    "f_values, p_values = selector_anova.scores_, selector_anova.pvalues_\n",
    "\n",
    "# Create a DataFrame to display features with their corresponding F-statistics and p-values\n",
    "anova_results = pd.DataFrame({'Feature': X_scaled_robust_train.columns,'F-Statistic': f_values, 'p-value': p_values})\n",
    "\n",
    "# Sort by F-statistic (highest to lowest) to find the most statistically significant features\n",
    "anova_results_sorted_by_F = anova_results.sort_values(by='F-Statistic', ascending=False)\n",
    "anova_results_sorted_by_F = anova_results_sorted_by_F[anova_results_sorted_by_F['Feature'].isin(anova_features)]\n",
    "print(anova_results_sorted_by_F)\n",
    "\n",
    "# Plot de F-statistic per feature\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(np.arange(1, len(anova_results_sorted_by_F) + 1), anova_results_sorted_by_F['F-Statistic'], marker='o')\n",
    "plt.xlabel(\"Feature Rank (Sorted by F-Statistic)\")\n",
    "plt.ylabel(\"F-Statistic Value\")\n",
    "plt.title(\"F-Statistic vs. Ranked Features (ANOVA)\")\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# Mutual Information (niet-lineaire relaties)\n",
    "selector_mi = SelectKBest(mutual_info_classif, k=100)\n",
    "X_filtered_mi = selector_mi.fit_transform(X_scaled_robust_train, y_train)\n",
    "mi_features = X_scaled_robust_train.columns[selector_mi.get_support()]\n",
    "\n",
    "# Gemeenschappelijke features\n",
    "common_features = list(set(anova_features).intersection(set(mi_features)))\n",
    "\n",
    "# Unieke features voor ANOVA en MI\n",
    "unique_anova = list(set(anova_features) - set(mi_features))\n",
    "unique_mi = list(set(mi_features) - set(anova_features))\n",
    "\n",
    "# Print de resultaten\n",
    "print(\"Selected features using ANOVA:\", anova_features)\n",
    "print(\"Selected features using Mutual Information:\", mi_features)\n",
    "print(\"Common features (selected by both ANOVA and MI):\", common_features)\n",
    "print(\"Unique features to ANOVA:\", unique_anova)\n",
    "print(\"Unique features to MI:\", unique_mi)\n",
    "print(len(common_features))\n",
    "\n",
    "# fig = plt.figure(figsize=(24,8))\n",
    "# ax = fig.add_subplot(131)\n",
    "# ax.set_title(\"First two features of ANOVA test\", fontsize='small')\n",
    "# scatter = ax.scatter(X_filtered_anova[:, 0], X_filtered_anova[:, 2], marker='o', c=y_train_numeric,\n",
    "#             s=25, edgecolor='k', cmap=plt.cm.Paired)\n",
    "\n",
    "# # Haal de juiste legenda-elementen op\n",
    "# handles, _ = scatter.legend_elements()\n",
    "# legend1 = ax.legend(handles, legend_labels, title=\"classes\")\n",
    "# ax.add_artist(legend1)\n",
    "# plt.show()\n",
    "\n",
    "example_features = anova_results_sorted_by_F.iloc[0:2]['Feature'].values\n",
    "fig = plt.figure(figsize=(8,8))\n",
    "plt.scatter(X_train[example_features[0]], X_train[example_features[1]], c=y_train_numeric, cmap=plt.cm.Paired, edgecolor='k')\n",
    "plt.xlabel(example_features[0])\n",
    "plt.ylabel(example_features[1])\n",
    "plt.title(f\"Scatter plot of 2 features: {example_features[0]} vs {example_features[1]}\")\n",
    "plt.grid(True)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Greedy feature selection, forward AFTER ANOVA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install mlxtend\n",
    "\n",
    "# Greedy feature selection (forward)\n",
    "\n",
    "# importing the models\n",
    "from sklearn.feature_selection import SequentialFeatureSelector\n",
    "from sklearn import svm\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "# calling the classifier for the feature selction\n",
    "clf = LogisticRegression(max_iter=500, random_state=42)\n",
    "svc = svm.SVC(kernel=\"linear\")\n",
    "\n",
    "# Stratified K-Fold cross-validation\n",
    "cv = StratifiedKFold(n_splits=3, shuffle=True, random_state=42)\n",
    "\n",
    "# Greedy forward selection and fitting (select 10 best features)\n",
    "sfs1 = SequentialFeatureSelector(clf, n_features_to_select=10, direction='forward', scoring='accuracy', cv=cv)\n",
    "sfs1.fit(X_train, y_train)\n",
    "\n",
    "# print selected feature names\n",
    "selected_features = X_train.columns[sfs1.get_support()]\n",
    "print(\"Selected features:\", selected_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apply RFECV/SFS after ANOVA selecting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Further Feature Selection with RFE\n",
    "\n",
    "# import modules\n",
    "from sklearn import feature_selection\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import svm\n",
    "\n",
    "# calling the classifier (SVM model or linear regression) for the feature selection\n",
    "svc = svm.SVC(kernel=\"linear\")\n",
    "# clf = LogisticRegression(max_iter=500, random_state=42)\n",
    "\n",
    "cv = model_selection.StratifiedKFold(n_splits=2, shuffle=True, random_state=42)\n",
    "\n",
    "# RFECV feature selection and fitting\n",
    "rfecv_anova = feature_selection.RFECV(estimator=svc,\n",
    "                                      step=5,\n",
    "                                      cv=cv,\n",
    "                                      scoring='roc_auc')\n",
    "\n",
    "rfecv_mi = feature_selection.RFECV(estimator=svc,\n",
    "                                   step=5,\n",
    "                                   cv=cv,\n",
    "                                   scoring='roc_auc')\n",
    "\n",
    "rfecv_anova.fit(X_filtered_anova, y_train)\n",
    "rfecv_mi.fit(X_filtered_mi, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print selected feature names and the number of features selected\n",
    "selected_features_anova = anova_features[rfecv_anova.support_]\n",
    "selected_features_mi = mi_features[rfecv_mi.support_]\n",
    "\n",
    "print(\"Features selected with ANOVA and RFECV:\", list(selected_features_anova))\n",
    "print(\"Features selected with MI and RFECV::\", list(selected_features_mi))\n",
    "\n",
    "print(\"Number of features selected with ANOVA and RFECV:\", sum(rfecv_anova.support_))\n",
    "print(\"Number of features  selected with MI and RFECV:\", sum(rfecv_mi.support_))\n",
    "\n",
    "# plot the number of features vs. accuracy\n",
    "plt.figure()\n",
    "plt.xlabel(\"Number of features selected\")\n",
    "plt.ylabel(\"Cross validation score (nb of correct classifications)\")\n",
    "plt.plot(range(1, len(rfecv_anova.cv_results_[\"mean_test_score\"]) + 1), rfecv_anova.cv_results_[\"mean_test_score\"], label=\"ANOVA + RFECV\", color=\"blue\")\n",
    "plt.plot(range(1, len(rfecv_mi.cv_results_[\"mean_test_score\"]) + 1), rfecv_mi.cv_results_[\"mean_test_score\"], label=\"MI + RFECV\", color=\"red\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inge: Optimization based feature selection > Lasso "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing Libraries for Lasso Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LassoCV\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import preprocessing\n",
    "from sklearn.decomposition import PCA\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Standardized scaling for Lasso Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def scaler_standardized (X_train, X_test):\n",
    "    \"\"\"\n",
    "    Scales the original training and test datasets using standardization (zero mean, unit variance). \n",
    "    \n",
    "    This function applies `StandardScaler` from `sklearn.preprocessing` to transform \n",
    "    `X_train` and `X_test`, which is necessary for Lasso feature selection and other \n",
    "    machine learning models that require standardized input.\n",
    "\n",
    "    Returns:\n",
    "        tuple: A tuple containing:\n",
    "            - `X_scaled_standard_train` (pd.DataFrame): The standardized training dataset.\n",
    "            - `X_scaled_standard_test` (pd.DataFrame): The standardized test dataset.\n",
    "    \n",
    "    Note:\n",
    "        The function assumes `X_train` and `X_test` are already defined globally.\n",
    "    \"\"\"\n",
    "    scaler_standard = preprocessing.StandardScaler()\n",
    "\n",
    "    scaled_standard_array_train = scaler_standard.fit_transform(X_train)\n",
    "    scaled_standard_array_test = scaler_standard.transform(X_test)\n",
    "\n",
    "    X_scaled_standard_train = pd.DataFrame(scaled_standard_array_train, columns=X_train.columns)\n",
    "    X_scaled_standard_test = pd.DataFrame(scaled_standard_array_test, columns=X_test.columns)\n",
    "    \n",
    "    return X_scaled_standard_train, X_scaled_standard_test\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Encode the categorical y-labels to numerical values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def y_numeric(y_train, y_test):\n",
    "    \"\"\"\n",
    "    Encodes categorical labels from `y_train` and `y_test` into numeric values using `LabelEncoder`.\n",
    "\n",
    "    This function applies `LabelEncoder` from `sklearn.preprocessing` to transform categorical target \n",
    "    labels into numerical format, which is essential for machine learning models that require numeric inputs.\n",
    "\n",
    "    Args:\n",
    "        y_train (pd.Series): The training labels.\n",
    "        y_test (pd.Series): The test labels.\n",
    "\n",
    "    Returns:\n",
    "        tuple: A tuple containing:\n",
    "            - `y_train_numeric` (numpy.ndarray): The transformed numeric labels for the training set.\n",
    "            - `y_test_numeric` (numpy.ndarray): The transformed numeric labels for the test set.\n",
    "\n",
    "    Prints:\n",
    "        - A dictionary mapping numeric labels to their corresponding original class names.\n",
    "\n",
    "    Note:\n",
    "        The function assumes `y_train` and `y_test` contain categorical labels.\n",
    "    \"\"\"\n",
    "    le = LabelEncoder()\n",
    "    y_train_numeric = le.fit_transform(y_train)\n",
    "    y_test_numeric = le.transform(y_test)\n",
    "\n",
    "    # Store the mapping of labels\n",
    "    legend_labels = le.classes_  # This saves the original class names\n",
    "    print(\"Label Mapping:\", {i: label for i, label in enumerate(legend_labels)})   \n",
    "    \n",
    "    return y_train_numeric, y_test_numeric\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Optimization based feature selection: LASSO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_scaled_standard_train = scaler_standardized (X_train, X_test) is this necessary?\n",
    "\n",
    "def lasso_fs(X_scaled_standard_train):\n",
    "    \"\"\"\n",
    "    Performs optimization based feature selection using Lasso regression.\n",
    "\n",
    "    This function applies Lasso regression with automatic hyperparameter tuning \n",
    "    (via `LassoCV`) to identify the most important features from the standardized training data.\n",
    "    It selects features by penalizing less important coefficients, setting some to zero.\n",
    "    \n",
    "    Args:\n",
    "        X_scaled_standard_train (pd.DataFrame): \n",
    "            The standardized training dataset with numerical features.\n",
    "\n",
    "    Returns:\n",
    "        tuple: A tuple containing:\n",
    "            - `X_train_selected` (np.ndarray): The reduced training dataset containing only selected features.\n",
    "            - `X_test_selected` (np.ndarray): The reduced test dataset containing only selected features.\n",
    "    \n",
    "    Prints:\n",
    "        - The best `alpha` value found through cross-validation.\n",
    "        - The names of the selected features.\n",
    "\n",
    "    Note:\n",
    "        - This function assumes `y_train_numeric` is globally defined.\n",
    "        - `SelectFromModel` is used to remove unimportant features based on the Lasso model.\n",
    "    \"\"\"\n",
    "    # Define LassoCV with cross-validation\n",
    "    n_alphas = 200\n",
    "    alphas = np.logspace(-10, -1, n_alphas)# Testing alpha from 0.0001 to 10\n",
    "    random_state = 42 #  Using int will produce the same results everytime, 42 is along 0 the most popular choice\n",
    "    lasso_cv = LassoCV(cv=5, alphas=alphas, random_state=random_state, max_iter=10000)  # TODO: cv = 5 chosen, what do we want?\n",
    "\n",
    "    # Fit LassoCV on training data\n",
    "    lasso_cv.fit(X_scaled_standard_train, y_train_numeric)\n",
    "\n",
    "    # Get the best alpha value\n",
    "    best_alpha = lasso_cv.alpha_\n",
    "\n",
    "    # Train final Lasso model with optimal alpha\n",
    "    lasso = Lasso(alpha=best_alpha, fit_intercept=False)\n",
    "    lasso.fit(X_scaled_standard_train, y_train_numeric)\n",
    "\n",
    "    # Select features\n",
    "    selector = SelectFromModel(lasso, prefit=True)\n",
    "    X_train_selected = selector.transform(X_scaled_standard_train)\n",
    "    X_test_selected = selector.transform(X_scaled_standard_train)\n",
    "\n",
    "    # Get selected feature indices and names\n",
    "    selected_features = np.where(selector.get_support())[0]\n",
    "    selected_feature_names = X_scaled_standard_train.columns[selected_features]\n",
    "    n_features = len(selected_features)\n",
    "    \n",
    "    return best_alpha, X_train_selected, X_test_selected, selected_feature_names, n_features\n",
    "\n",
    "# Capture the return values when calling the function\n",
    "best_alpha, X_train_sel, X_test_sel, selected_feature_names, n_features = lasso_fs(X_scaled_standard_train)\n",
    "\n",
    "# Print the captured values in the global scope\n",
    "print(f\"Best alpha found: {best_alpha}\")\n",
    "print(\"Selected Features:\", selected_feature_names)\n",
    "print(f\"N features found: {n_features}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PCA feature extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_alpha, X_train_sel, X_test_sel, selected_feature_names, n_features = lasso_fs(X_scaled_standard_train)\n",
    "\n",
    "def PCA_fs(X_scaled_robust_train, X_scaled_robust_test, n_features):\n",
    "    \"\"\"\n",
    "    Performs Principal Component Analysis (PCA) for feature reduction.\n",
    "\n",
    "    This function applies PCA to reduce the dimensionality of the input data, \n",
    "    transforming the training and test datasets to a lower number of features \n",
    "    (specified by `n_features`), while retaining as much variance as possible.\n",
    "\n",
    "    Args:\n",
    "        n_features (int): \n",
    "            The number of principal components to retain after performing PCA.\n",
    "            Based on the number of features of Lasso.\n",
    "\n",
    "    Returns:\n",
    "        tuple: A tuple containing:\n",
    "            - `X_scaled_standard_train_PCA` (np.ndarray): The transformed training dataset with reduced features.\n",
    "            - `X_scaled_standard_test_PCA` (np.ndarray): The transformed test dataset with reduced features.\n",
    "\n",
    "    Notes:\n",
    "        - The function assumes `X_scaled_robust_train` and `X_scaled_robust_test` are predefined globally.\n",
    "        - The function applies the same transformation to both the training and test datasets, \n",
    "          ensuring that the test set is projected into the same lower-dimensional space as the training set.\n",
    "    \"\"\"\n",
    "    pca = PCA(n_components=n_features)\n",
    "    X_train_PCA = pca.fit_transform(X_scaled_robust_train)\n",
    "    X_test_PCA = pca.transform(X_scaled_robust_test)  # Use the same transformation\n",
    "    return X_train_PCA, X_test_PCA\n",
    "\n",
    "# Assuming you already have the transformed PCA data\n",
    "X_train_pca, X_test_pca = PCA_fs(X_scaled_robust_train, X_scaled_robust_test, n_features=7) \n",
    "best_alpha, X_train_sel, X_test_sel, selected_feature_names, n_features = lasso_fs(X_scaled_standard_train)\n",
    "\n",
    "# Plotting the first two principal components of the training data\n",
    "plt.scatter(X_train_pca[:, 0], X_train_pca[:, 1], c=y_train_numeric)\n",
    "plt.title('PCA - Training Data')\n",
    "plt.xlabel(selected_feature_names[0])\n",
    "plt.ylabel(selected_feature_names[1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing feature selections "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# General packages\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import datasets as ds\n",
    "from sklearn import metrics\n",
    "\n",
    "# Classifiers\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Zet de labels om naar numerieke waarden\n",
    "le = LabelEncoder()\n",
    "y_train = le.fit_transform(y_train)  # Zet 'lipoma' en 'liposarcoma' om naar 0 en 1\n",
    "y_test = le.transform(y_test)  # Pas dezelfde transformatie toe op y_test\n",
    "\n",
    "# Define the classifiers\n",
    "classifiers = [\n",
    "    LinearDiscriminantAnalysis(),\n",
    "    QuadraticDiscriminantAnalysis(),\n",
    "    GaussianNB(),\n",
    "    LogisticRegression(max_iter=5000),\n",
    "    SGDClassifier(max_iter=5000, tol=1e-3),\n",
    "    KNeighborsClassifier(n_neighbors=40),\n",
    "    DecisionTreeClassifier(random_state=42)\n",
    "]\n",
    "\n",
    "# Store fitted classifiers\n",
    "clfs_fit = []\n",
    "\n",
    "# Select the same features for the test set\n",
    "X_train_selected = X_filtered_anova  # Train-set met ANOVA-geselecteerde features\n",
    "X_test_selected = selector_anova.transform(X_test)  # Test-set met ANOVA-features\n",
    "\n",
    "# Train and evaluate classifiers\n",
    "for clf in classifiers:\n",
    "    # Train classifier\n",
    "    clf.fit(X_scaled_robust_train, y_train)\n",
    "    Y_pred = clf.predict(X_scaled_robust_test)\n",
    "\n",
    "    # Store fitted classifier\n",
    "    clfs_fit.append(clf)\n",
    "\n",
    "    # Compute evaluation metrics\n",
    "    accuracy = metrics.accuracy_score(y_test, Y_pred)\n",
    "\n",
    "    if hasattr(clf, 'predict_proba'):\n",
    "        y_score = clf.predict_proba(X_scaled_robust_test)[:, 1]  # Probability for class 1\n",
    "    else:\n",
    "        y_score = Y_pred  # Use binary predictions if probability is unavailable\n",
    "\n",
    "    auc = metrics.roc_auc_score(y_test, y_score)\n",
    "    f1 = metrics.f1_score(y_test, Y_pred)\n",
    "    precision = metrics.precision_score(y_test, Y_pred)\n",
    "    recall = metrics.recall_score(y_test, Y_pred)\n",
    "\n",
    "    # Print the results\n",
    "    print(f\"Classifier: {clf.__class__.__name__}\")\n",
    "    print(f\"  Accuracy: {accuracy:.4f}\")\n",
    "    print(f\"  AUC: {auc:.4f}\")\n",
    "    print(f\"  F1-Score: {f1:.4f}\")\n",
    "    print(f\"  Precision: {precision:.4f}\")\n",
    "    print(f\"  Recall: {recall:.4f}\")\n",
    "    print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model selection\n",
    "Random forest, decision tree and bagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import randint\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier, BaggingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Encode categorical labels\n",
    "label_encoder = LabelEncoder()\n",
    "y_train_encoded = label_encoder.fit_transform(y_train)\n",
    "\n",
    "# Define models and parameter distributions\n",
    "models = {\n",
    "    \"Random Forest\": (RandomForestClassifier(), {\n",
    "        'n_estimators': randint(5, 200),\n",
    "        'max_depth': randint(3, 30),\n",
    "        'min_samples_split': randint(2, 20),\n",
    "        'bootstrap': [True, False]\n",
    "    }),\n",
    "    \"Bagging\": (BaggingClassifier(DecisionTreeClassifier()), {\n",
    "        'n_estimators': randint(5, 200),\n",
    "        'estimator__max_depth': randint(3, 30),\n",
    "        'estimator__min_samples_split': randint(2, 20),\n",
    "        'bootstrap': [True, False]\n",
    "    }),\n",
    "    \"Decision Tree\": (DecisionTreeClassifier(), {\n",
    "        'max_depth': randint(3, 30),\n",
    "        'min_samples_split': randint(2, 20)\n",
    "    })\n",
    "}\n",
    "\n",
    "# Perform Randomized Search and store results\n",
    "best_estimators = {}\n",
    "best_params = {}\n",
    "best_scores = {}\n",
    "\n",
    "for name, (model, param_dist) in models.items():\n",
    "    search = RandomizedSearchCV(\n",
    "        estimator=model,\n",
    "        param_distributions=param_dist,\n",
    "        n_iter=30,\n",
    "        scoring='accuracy',\n",
    "        cv=10,\n",
    "        n_jobs=-1,\n",
    "        random_state=42\n",
    "    )\n",
    "    search.fit(X_train, y_train_encoded) # Fitted on data without scaling and feature selection\n",
    "    \n",
    "    best_estimators[name] = search.best_estimator_\n",
    "    best_params[name] = search.best_params_\n",
    "    best_scores[name] = search.best_score_\n",
    "\n",
    "# Print results\n",
    "print(\"\\n=== Model Comparison ===\")\n",
    "for model_name in models.keys():\n",
    "    print(f\"\\nBest {model_name}: {best_estimators[model_name]}\")\n",
    "    print(f\"Best {model_name} Parameters: {best_params[model_name]}\")\n",
    "    print(f\"Best {model_name} Accuracy: {best_scores[model_name]:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "# Define base SVM model\n",
    "svm_model = SVC()\n",
    "\n",
    "# Define parameter distribution for RandomizedSearchCV\n",
    "param_dist = {\n",
    "    'C': [0.1, 1, 10, 100, 1000],  # Regularization parameter\n",
    "    'gamma': ['scale', 'auto', 0.1, 1, 10, 100],  # Kernel coefficient\n",
    "    'kernel': ['linear', 'rbf', 'poly'],  # Different kernel types\n",
    "    'degree': [1, 2, 3, 4, 5, 6],  # Only used for poly kernel\n",
    "}\n",
    "\n",
    "#TIJDELIJK TODO weghalen\n",
    "X_small = X_scaled_robust_train.iloc[:, [100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110]]  # First 10 features\n",
    "\n",
    "# Randomized Search with cv=10\n",
    "random_search = RandomizedSearchCV(\n",
    "    estimator=svm_model,\n",
    "    param_distributions=param_dist,\n",
    "    n_iter=30,  # More iterations for better results\n",
    "    scoring='accuracy',\n",
    "    cv=10,  # 10-fold cross-validation\n",
    "    n_jobs=-1,  # Use all CPU cores\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Fit on robustly scaled training data\n",
    "random_search.fit(X_small, y_train_encoded) #TODO data nog veranderen\n",
    "\n",
    "# Get the best model and parameters\n",
    "best_svm = random_search.best_estimator_\n",
    "best_params_svm = random_search.best_params_\n",
    "best_score_svm = random_search.best_score_\n",
    "\n",
    "# Print results\n",
    "print(\"\\n=== Best SVM Model After Randomized Search ===\")\n",
    "print(f\"Best SVM: {best_svm}\")\n",
    "print(f\"Best SVM Parameters: {best_params_svm}\")\n",
    "print(f\"Best SVM Accuracy: {best_score_svm:.4f}\")\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "assignment.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
