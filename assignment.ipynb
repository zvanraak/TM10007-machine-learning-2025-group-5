{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7SXpaKwwGe5x"
   },
   "source": [
    "# TM10007 Assignment template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 69
    },
    "colab_type": "code",
    "id": "CiDn2Sk-VWqE",
    "outputId": "64224cd2-6054-4b04-a3f6-af8290400dfc"
   },
   "outputs": [],
   "source": [
    "# Run this to use from colab environment\n",
    "#!pip install -q --upgrade git+https://github.com/jveenland/tm10007_ml.git"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data loading and cleaning\n",
    "\n",
    "Below are functions to load the dataset of your choice. After that, it is all up to you to create and evaluate a classification method. Beware, there may be missing values in these datasets. Good luck!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-NE_fTbKGe5z"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of samples: 115\n",
      "The number of columns: 494\n",
      "Fold 1:\n",
      " - Train size: 73\n",
      " - Validation size: 19\n",
      "Fold 2:\n",
      " - Train size: 73\n",
      " - Validation size: 19\n",
      "Fold 3:\n",
      " - Train size: 74\n",
      " - Validation size: 18\n",
      "Fold 4:\n",
      " - Train size: 74\n",
      " - Validation size: 18\n",
      "Fold 5:\n",
      " - Train size: 74\n",
      " - Validation size: 18\n"
     ]
    }
   ],
   "source": [
    "# Data loading functions. Uncomment the one you want to use\n",
    "#from worcgist.load_data import load_data\n",
    "from worclipo.load_data import load_data\n",
    "#from worcliver.load_data import load_data\n",
    "#from ecg.load_data import load_data\n",
    "\n",
    "# Import classifiers\n",
    "from sklearn import model_selection\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "\n",
    "\n",
    "data = load_data()\n",
    "print(f'The number of samples: {len(data.index)}')\n",
    "print(f'The number of columns: {len(data.columns)}')\n",
    "\n",
    "X = data.drop(\"label\",axis=1)\n",
    "y = data[\"label\"]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "for fold, (train_idx, val_idx) in enumerate(skf.split(X_train, y_train), 1):\n",
    "    X_train_fold = X_train.iloc[train_idx]\n",
    "    y_train_fold = y_train.iloc[train_idx]\n",
    "    X_val_fold = X_train.iloc[val_idx]\n",
    "    y_val_fold = y_train.iloc[val_idx]\n",
    "\n",
    "    print(f\"Fold {fold}:\")\n",
    "    print(f\" - Train size: {len(X_train_fold)}\")\n",
    "    print(f\" - Validation size: {len(X_val_fold)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Missing data\n",
    "* Part 1: Finding missing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Series([], dtype: int64)\n"
     ]
    }
   ],
   "source": [
    "# Define missing value indicators\n",
    "custom_missing = ['NA', 'N/A', '?', 'None', 'none', '-']\n",
    "\n",
    "# Count NaNs\n",
    "nan_counts = X_train.isna().sum()\n",
    "\n",
    "# Count empty strings\n",
    "empty_string_counts = (X_train == '').sum()\n",
    "\n",
    "# Count custom missing indicators (case-insensitive match)\n",
    "custom_missing_counts = X_train.apply(lambda col: col.astype(str).str.lower().isin([val.lower() for val in custom_missing]).sum())\n",
    "\n",
    "# Compute total missing count per column\n",
    "total_missing = nan_counts + empty_string_counts + custom_missing_counts\n",
    "\n",
    "# Filter out columns where total missing is zero\n",
    "total_missing_selected = total_missing[total_missing != 0]\n",
    "\n",
    "# Print total missing counts\n",
    "print(total_missing_selected)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Part 2: Processing missing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import\n",
    "import numpy as np\n",
    "from sklearn.impute import SimpleImputer\n",
    "from scipy.stats import shapiro\n",
    "\n",
    "# Replacing missing values with NaN\n",
    "custom_missing = ['NA', 'N/A', '?', 'None', 'none', '-', '']\n",
    "X_train.replace(custom_missing, np.nan, inplace=True)\n",
    "X_test.replace(custom_missing, np.nan, inplace=True)\n",
    "\n",
    "# If 50% or more of the data within one feature is missing the feature is deleted\n",
    "limit = len(X_train.index)*50/100\n",
    "valid_columns = [col for col, count in total_missing.items() if count < limit]\n",
    "\n",
    "# Keep only the valid columns in both X_train and X_test\n",
    "X_train = X_train[valid_columns]\n",
    "X_test = X_test[valid_columns]\n",
    "\n",
    "# Imputate \n",
    "\n",
    "# Check if imputation is needed\n",
    "if X_train.isna().sum().sum() == 0:\n",
    "    pass\n",
    "else:\n",
    "    # Dictionary to store mean/median decision per column\n",
    "    imputation_strategies = {}\n",
    "\n",
    "    for col in X_train.select_dtypes(include=['number']).columns:  # Only numeric columns\n",
    "        col_data = X_train[col].dropna()  # Remove NaN values for testing\n",
    "\n",
    "        if len(col_data) > 3:  # Shapiro requires at least 3 non-null values\n",
    "            if col_data.nunique() == 1:  # Check if all values are the same\n",
    "                strategy = 'median'  # Default to median if no variability\n",
    "            else:\n",
    "                _, p = shapiro(col_data)\n",
    "                strategy = 'mean' if p > 0.05 else 'median'\n",
    "        else:\n",
    "            strategy = 'median'  # Default to median if too few values\n",
    "\n",
    "        imputation_strategies[col] = strategy\n",
    "\n",
    "    # Create imputers for mean and median\n",
    "    mean_imputer = SimpleImputer(strategy='mean')\n",
    "    median_imputer = SimpleImputer(strategy='median')\n",
    "\n",
    "    # Apply imputers for each feature\n",
    "    for col, strategy in imputation_strategies.items():\n",
    "        imputer = mean_imputer if strategy == 'mean' else median_imputer\n",
    "        X_train[col] = imputer.fit_transform(X_train[[col]])\n",
    "        X_test[col] = imputer.transform(X_test[[col]])  # Use the same imputer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scaling data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    PREDICT_original_sf_compactness_avg_2.5D  \\\n",
      "0                                   0.311125   \n",
      "1                                  -0.711701   \n",
      "2                                   0.909548   \n",
      "3                                  -0.094719   \n",
      "4                                   0.841177   \n",
      "..                                       ...   \n",
      "81                                 -0.882556   \n",
      "82                                 -0.900222   \n",
      "83                                 -0.081870   \n",
      "84                                  1.175088   \n",
      "85                                  0.240824   \n",
      "\n",
      "    PREDICT_original_sf_compactness_std_2.5D  \\\n",
      "0                                  -0.017272   \n",
      "1                                   0.162159   \n",
      "2                                  -0.333623   \n",
      "3                                   0.117707   \n",
      "4                                  -0.563987   \n",
      "..                                       ...   \n",
      "81                                  0.330932   \n",
      "82                                  0.506205   \n",
      "83                                 -0.533812   \n",
      "84                                 -1.039117   \n",
      "85                                  0.643349   \n",
      "\n",
      "    PREDICT_original_sf_rad_dist_avg_2.5D  \\\n",
      "0                               -0.290374   \n",
      "1                                2.973356   \n",
      "2                                0.470754   \n",
      "3                                1.810182   \n",
      "4                                1.534216   \n",
      "..                                    ...   \n",
      "81                               0.136668   \n",
      "82                               3.257412   \n",
      "83                              -1.098606   \n",
      "84                               0.054466   \n",
      "85                               1.003553   \n",
      "\n",
      "    PREDICT_original_sf_rad_dist_std_2.5D  \\\n",
      "0                               -0.625588   \n",
      "1                                4.607077   \n",
      "2                               -0.758343   \n",
      "3                                2.247714   \n",
      "4                                0.199632   \n",
      "..                                    ...   \n",
      "81                               0.087952   \n",
      "82                               2.603809   \n",
      "83                              -0.823070   \n",
      "84                              -0.775398   \n",
      "85                               0.285004   \n",
      "\n",
      "    PREDICT_original_sf_roughness_avg_2.5D  \\\n",
      "0                                -0.503757   \n",
      "1                                 0.606347   \n",
      "2                                -0.854490   \n",
      "3                                 0.573255   \n",
      "4                                -0.644543   \n",
      "..                                     ...   \n",
      "81                                1.308424   \n",
      "82                                1.208556   \n",
      "83                               -0.430782   \n",
      "84                               -0.720802   \n",
      "85                               -0.193172   \n",
      "\n",
      "    PREDICT_original_sf_roughness_std_2.5D  \\\n",
      "0                                -0.298036   \n",
      "1                                 0.782171   \n",
      "2                                -0.613996   \n",
      "3                                 0.386289   \n",
      "4                                -0.462839   \n",
      "..                                     ...   \n",
      "81                                1.556848   \n",
      "82                                2.315382   \n",
      "83                               -0.534609   \n",
      "84                               -0.637109   \n",
      "85                                0.162037   \n",
      "\n",
      "    PREDICT_original_sf_convexity_avg_2.5D  \\\n",
      "0                                 0.043969   \n",
      "1                                -0.636964   \n",
      "2                                 0.361690   \n",
      "3                                 0.027230   \n",
      "4                                 0.444658   \n",
      "..                                     ...   \n",
      "81                               -1.404694   \n",
      "82                               -1.630506   \n",
      "83                                0.228418   \n",
      "84                                0.600269   \n",
      "85                               -0.169134   \n",
      "\n",
      "    PREDICT_original_sf_convexity_std_2.5D  PREDICT_original_sf_cvar_avg_2.5D  \\\n",
      "0                                -0.168670                          -0.497335   \n",
      "1                                 0.233081                           1.266520   \n",
      "2                                -0.471385                          -0.920996   \n",
      "3                                 0.117470                           0.623021   \n",
      "4                                -0.620463                          -0.653242   \n",
      "..                                     ...                                ...   \n",
      "81                                0.658141                           0.003175   \n",
      "82                                0.893495                           0.066797   \n",
      "83                               -0.484329                           0.609141   \n",
      "84                               -0.907417                          -0.835966   \n",
      "85                                0.656236                          -0.334677   \n",
      "\n",
      "    PREDICT_original_sf_cvar_std_2.5D  ...  \\\n",
      "0                           -0.461895  ...   \n",
      "1                            0.713537  ...   \n",
      "2                           -1.075493  ...   \n",
      "3                            0.456621  ...   \n",
      "4                           -0.678835  ...   \n",
      "..                                ...  ...   \n",
      "81                          -0.241134  ...   \n",
      "82                           0.753347  ...   \n",
      "83                           1.126232  ...   \n",
      "84                          -0.876152  ...   \n",
      "85                          -0.104594  ...   \n",
      "\n",
      "    PREDICT_original_phasef_phasesym_median_WL3_N5  \\\n",
      "0                                         2.287106   \n",
      "1                                         0.000000   \n",
      "2                                         0.000000   \n",
      "3                                         0.000000   \n",
      "4                                         0.000000   \n",
      "..                                             ...   \n",
      "81                                        0.567028   \n",
      "82                                        0.000000   \n",
      "83                                        0.000000   \n",
      "84                                        0.000000   \n",
      "85                                        0.000000   \n",
      "\n",
      "    PREDICT_original_phasef_phasesym_std_WL3_N5  \\\n",
      "0                                      0.348609   \n",
      "1                                      0.218387   \n",
      "2                                     -0.166153   \n",
      "3                                     -0.027372   \n",
      "4                                     -0.925136   \n",
      "..                                          ...   \n",
      "81                                     0.228274   \n",
      "82                                    -0.260362   \n",
      "83                                     0.394323   \n",
      "84                                    -0.563025   \n",
      "85                                    -1.264149   \n",
      "\n",
      "    PREDICT_original_phasef_phasesym_skewness_WL3_N5  \\\n",
      "0                                          -0.383366   \n",
      "1                                          -0.053610   \n",
      "2                                           0.095110   \n",
      "3                                           0.179010   \n",
      "4                                           1.241099   \n",
      "..                                               ...   \n",
      "81                                         -0.116281   \n",
      "82                                          0.658346   \n",
      "83                                         -0.290914   \n",
      "84                                          0.212613   \n",
      "85                                          1.674775   \n",
      "\n",
      "    PREDICT_original_phasef_phasesym_kurtosis_WL3_N5  \\\n",
      "0                                          -0.290081   \n",
      "1                                          -0.078527   \n",
      "2                                           0.071294   \n",
      "3                                           0.141390   \n",
      "4                                           1.443092   \n",
      "..                                               ...   \n",
      "81                                         -0.097381   \n",
      "82                                          0.651542   \n",
      "83                                         -0.322800   \n",
      "84                                          0.289243   \n",
      "85                                          2.239805   \n",
      "\n",
      "    PREDICT_original_phasef_phasesym_peak_WL3_N5  \\\n",
      "0                                            0.0   \n",
      "1                                            0.0   \n",
      "2                                            0.0   \n",
      "3                                            0.0   \n",
      "4                                            0.0   \n",
      "..                                           ...   \n",
      "81                                           0.0   \n",
      "82                                           0.0   \n",
      "83                                           0.0   \n",
      "84                                           0.0   \n",
      "85                                           0.0   \n",
      "\n",
      "    PREDICT_original_phasef_phasesym_peak_position_WL3_N5  \\\n",
      "0                                                 0.0       \n",
      "1                                                 0.0       \n",
      "2                                                 0.0       \n",
      "3                                                 0.0       \n",
      "4                                                 0.0       \n",
      "..                                                ...       \n",
      "81                                                0.0       \n",
      "82                                                0.0       \n",
      "83                                                0.0       \n",
      "84                                                0.0       \n",
      "85                                                0.0       \n",
      "\n",
      "    PREDICT_original_phasef_phasesym_range_WL3_N5  \\\n",
      "0                                        0.306292   \n",
      "1                                        0.235205   \n",
      "2                                       -0.230848   \n",
      "3                                        0.018719   \n",
      "4                                       -0.916563   \n",
      "..                                            ...   \n",
      "81                                       0.313506   \n",
      "82                                      -0.120378   \n",
      "83                                       0.251465   \n",
      "84                                      -0.664733   \n",
      "85                                      -1.399039   \n",
      "\n",
      "    PREDICT_original_phasef_phasesym_energy_WL3_N5  \\\n",
      "0                                         0.255447   \n",
      "1                                         4.626823   \n",
      "2                                         0.999524   \n",
      "3                                         2.531681   \n",
      "4                                         0.440317   \n",
      "..                                             ...   \n",
      "81                                        0.786300   \n",
      "82                                        2.591180   \n",
      "83                                       -0.494708   \n",
      "84                                        0.005520   \n",
      "85                                       -0.368800   \n",
      "\n",
      "    PREDICT_original_phasef_phasesym_quartile_range_WL3_N5  \\\n",
      "0                                            0.421226        \n",
      "1                                            0.171015        \n",
      "2                                           -0.059551        \n",
      "3                                           -0.059011        \n",
      "4                                           -1.004754        \n",
      "..                                                ...        \n",
      "81                                           0.220912        \n",
      "82                                          -0.428220        \n",
      "83                                           0.346022        \n",
      "84                                          -0.207842        \n",
      "85                                          -1.064067        \n",
      "\n",
      "    PREDICT_original_phasef_phasesym_entropy_WL3_N5  \n",
      "0                                          0.212310  \n",
      "1                                          1.332169  \n",
      "2                                          0.762152  \n",
      "3                                          1.100598  \n",
      "4                                          0.664562  \n",
      "..                                              ...  \n",
      "81                                         0.542512  \n",
      "82                                         1.131605  \n",
      "83                                        -1.637839  \n",
      "84                                         0.356109  \n",
      "85                                        -0.238192  \n",
      "\n",
      "[86 rows x 493 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn import preprocessing\n",
    "\n",
    "scaler_robust = preprocessing.RobustScaler()\n",
    "\n",
    "scaled_robust_array_train = scaler_robust.fit_transform(X_train)\n",
    "scaled_robust_array_test = scaler_robust.transform(X_test)\n",
    "\n",
    "X_scaled_robust_train = pd.DataFrame(scaled_robust_array_train, columns=X_train.columns)\n",
    "X_scaled_robust_test = pd.DataFrame(scaled_robust_array_test, columns=X_test.columns)\n",
    "\n",
    "# print(X_scaled_robust_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feature extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lloyd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model selection\n",
    "Random forest, decision tree and bagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 20 candidates, totalling 200 fits\n",
      "Fitting 10 folds for each of 20 candidates, totalling 200 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\loisb\\miniconda3\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:317: UserWarning: The total space of parameters 11 is smaller than n_iter=20. Running 11 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 11 candidates, totalling 110 fits\n",
      "\n",
      "=== Model Comparison ===\n",
      "Best Random Forest: RandomForestClassifier(bootstrap=False, max_depth=40, n_estimators=156)\n",
      "Best RF Parameters: {'bootstrap': False, 'max_depth': 40, 'n_estimators': 156}\n",
      "Best RF Accuracy: 0.7764\n",
      "\n",
      "Best Bagging Classifier: BaggingClassifier(estimator=DecisionTreeClassifier(), n_estimators=25)\n",
      "Best Bagging Parameters: {'bootstrap': True, 'n_estimators': 25}\n",
      "Best Bagging Accuracy: 0.8000\n",
      "\n",
      "Best Decision Tree Classifier: DecisionTreeClassifier(max_depth=18)\n",
      "Best Decision Tree Parameters: {'max_depth': 18}\n",
      "Best Decision Tree Accuracy: 0.7792\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import randint\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier, BaggingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Encode categorical labels\n",
    "label_encoder = LabelEncoder()\n",
    "y_train_encoded = label_encoder.fit_transform(y_train)\n",
    "\n",
    "# Define models and parameter distributions\n",
    "models = {\n",
    "    \"Random Forest\": (RandomForestClassifier(), {\n",
    "        'n_estimators': randint(5, 200),\n",
    "        'max_depth': randint(3, 30),\n",
    "        'min_samples_split': randint(2, 20),\n",
    "        'bootstrap': [True, False]\n",
    "    }),\n",
    "    \"Bagging\": (BaggingClassifier(DecisionTreeClassifier()), {\n",
    "        'n_estimators': randint(5, 200),\n",
    "        'estimator__max_depth': randint(3, 30),\n",
    "        'estimator__min_samples_split': randint(2, 20),\n",
    "        'bootstrap': [True, False]\n",
    "    }),\n",
    "    \"Decision Tree\": (DecisionTreeClassifier(), {\n",
    "        'max_depth': randint(3, 30),\n",
    "        'min_samples_split': randint(2, 20)\n",
    "    })\n",
    "}\n",
    "\n",
    "# Perform Randomized Search and store results\n",
    "best_estimators = {}\n",
    "best_params = {}\n",
    "best_scores = {}\n",
    "\n",
    "for name, (model, param_dist) in models.items():\n",
    "    search = RandomizedSearchCV(\n",
    "        estimator=model,\n",
    "        param_distributions=param_dist,\n",
    "        n_iter=20,\n",
    "        scoring='accuracy',\n",
    "        cv=10,\n",
    "        n_jobs=-1,\n",
    "        random_state=42\n",
    "    )\n",
    "    search.fit(X_train, y_train_encoded)\n",
    "    \n",
    "    best_estimators[name] = search.best_estimator_\n",
    "    best_params[name] = search.best_params_\n",
    "    best_scores[name] = search.best_score_\n",
    "\n",
    "# Print results\n",
    "print(\"\\n=== Model Comparison ===\")\n",
    "print(f\"Best Random Forest: {best_rf}\")\n",
    "print(f\"Best RF Parameters: {best_params_rf}\")\n",
    "print(f\"Best RF Accuracy: {best_score_rf:.4f}\")\n",
    "\n",
    "print(f\"\\nBest Bagging Classifier: {best_bagging}\")\n",
    "print(f\"Best Bagging Parameters: {best_params_bagging}\")\n",
    "print(f\"Best Bagging Accuracy: {best_score_bagging:.4f}\")\n",
    "\n",
    "print(f\"\\nBest Decision Tree Classifier: {best_dt}\")\n",
    "print(f\"Best Decision Tree Parameters: {best_params_dt}\")\n",
    "print(f\"Best Decision Tree Accuracy: {best_score_dt:.4f}\")\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "assignment.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
